 # Statistical Natural Language Processing Seminar -- 2021 Spring

Time: **18:00 pm, Tuesday**

Venue: Tin Ka Ping Building 302 (田家炳楼302)

Welcome to StatNLP Seminar 2021 Spring. : )

## On Papers

- Please choose recent papers (2021, 2020, 2019) from top NLP/AI venues. A (incomplete) list is
  - NLP: ACL, TACL, EMNLP, NAACL, EACL
  - ML:  ICML, NeurIPS, AISTATS, JMLR, ICLR
  - AI:  AAAI, IJCAI
  - IR/DM: SIGIR, CIKM, WSDM, KDD, WWW

- While we are interested in a broad range of NLP/AI topics, the followings (and a list [here](https://slack-files.com/T22T1UP8Q-FLT6K0WDV-c037db5283)) are of great importance
  - syntactic/semantic parsing
  - entity/relation/event extraction
  - distributed/distributional/compositional semantics
  - MT/QA/Dialog
  - (deep) learning algorithms

- Materials with broad interests are welcome (e.g., tutorials form top conferences, high-quality surveys).

## For Presenters

- Please fill your slots in the [Agenda](#agenda) **at least one week** before your presentation.
  - Please format Paper fields with *[venue+year]title* (e.g. [ACL21]A Good Paper).
  - Please upload your slides, and add links to them in Slides fields.
- Besides technical novelties, please give enough background knowledge in case people are unfamiliar with your topic.
- It would be great to keep your presentation within 60 min.

## For Audiences

- Please read abstract/introduction sections before the seminar.

## Agenda

Week   | Date | Speaker   | Paper   | Materials
:---:  | :---: | :---: | --- | :---:
1      |  3.2 | 杨晰 | [Survey] GNN for Information Extraction  | 
2      |  3.9 | 高怡 | [Survey] Few Shot Learning | 
3      |  3.16 | 李东阳 | [ACL20]Dialogue-Based Relation Extraction | 
3      |  3.16 |  刘申 | [EMNLP20]Understanding Procedural Text using Interactive Entity Networks | 
4      |  3.23 | 张亚东 | [EMNLP20]Experience Grounds Language | 
4      |  3.23 | 蔡丽 | [EMNLP20]ETC: Encoding Long and Structured Inputs in Transformers | 
5      |  3.30 | 陈少斌 | [EMNLP20]Zero-Shot Cross-Lingual Transfer with Meta Learning |
5      |  3.30 | 张雨时 | [EMNLP20]How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue | 
6      |  4.6 | 但宇豪 | [EMNLP20]Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start | 
6      |  4.6 | 陈妍 | [EMNLP20]Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models | 
7      |  4.13 | 凌静 | [AAAI2020]Differentiable Reasoning on Large Knowledge Bases and Natural Language | 
7      |  4.13 | 谭振东 | [EMNLP20]Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks | 
8      |  4.20 |  李东阳 | [EMNLP20]Event Extraction by Answering (Almost) Natural Questions | 
8      |  4.20 |  刘申 | [EMNLP20]Denoising Relation Extraction from Document-level Distant Supervision | 
9      |  4.27 | 张亚东 | [EMNLP20]Visually Grounded Compound PCFGs | 
9      |  4.27 | 蔡丽 | [EMNLP20]Calibration of Pre-trained Transformers | 
10      |  5.4 | 陈少斌 | [ACL2020]On the Cross-lingual Transferability of Monolingual Representations | 
10      |  5.4 | 张雨时 | [ACL20]Automatic Detection of Generated Text is Easiest when Humans are Fooled | 
11      |  5.11 | 但宇豪 | [EMNLP20]Text Classiﬁcation Using Label Names Only: A Language Model Self-Training Approach | 
11      |  5.11 | 陈妍 | [EMNLP20] Self-Supervised Knowledge Triplet Learning for Zero-Shot Question Answering | 
12      |  5.18 | 凌静 | [ICLR20] Scalable Neural Methods for Reasoning with a Symbolic Knowledge Base | 
12      |  5.18 | 谭振东 |[EMNLP20]A Diagnostic Study of Explainability Techniques for Text Classification  | 
13      |  5.25 | ~~蔡泽锋 | [EMNLP20] What do Models Learn from Question Answering Datasets?~~| 
13      |  5.25 | ~~蔡泽锋 | [EMNLP20] Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers~~ | 
13      |       |       | [EMNLP20] Stolen Probability: A Structural Weakness of Neural Language Models | 
14      |  6.1 | 杨晰 | [EMNLP20]How Much Knowledge Can You Pack Into the Parameters of a Language Model? | 
14      |  6.1 | 高怡 | [ACL20]Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness? | 
15      |  6.8 | 刘申 | [EMNLP20]Exposing Shallow Heuristics of Relation Extraction Models with Challenge Data | 
15      |  6.8 | 张亚东 | [EMNLP20]Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision | 
16      |  6.15 | 陈少斌 | [EMNLP2020]Zero-Shot Crosslingual Sentence Simplification | 
16      |  6.15 | 张雨时 | [ACL2020]Paraphrase Augmented Task-Oriented Dialog Generation | 
17      |  6.22 | 但宇豪 | [EMNLP20]Active Learning for BERT: An Empirical Study | 
17      |  6.22 | 凌静 |[EMNLP20]Distilling Structured Knowledge for Text-Based Relational Reasoning  | 


---
## F.A.Q.

1. How to fill the slots and upload your slides?
- [creating-a-pull-request-from-a-fork/](https://help.github.com/articles/creating-a-pull-request-from-a-fork/)
- or you can contact:
  - Peng Li, <ruhao9805@gmail.com>
  - Tao Ji, <taoji.cs@gmail.com>
  - Yang Wei, <i@godweiyang.com>
- any quesitons, please feel free to contact us.
