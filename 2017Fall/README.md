# AntNLP Seminar -- 2017 Fall

Time: 18:00 pm, Wednesday

Venue: - TBD


## On Papers
- Please choose recent papers (2017, 2016) from top NLP/AI venues. A (incomplete) list is
  - NLP: ACL, TACL, EMNLP, NAACL, EACL  
  - ML:  ICML, NIPS, AISTATS, JMLR, ICLR  
  - AI:  AAAI, IJCAI  
  - IR/DM: SIGIR, CIKM, WSDM, KDD, WWW  
- While we are interested in a broad range of NLP/AI topics, the followings 
(and a list [here](https://slack-files.com/T22T1UP8Q-F726RJERH-9a39cc3d9a)) are of great importance
  - syntactic/semantic parsing  
  - entity/relation/event extraction  
  - distributed/distributional/compositional semantics
  - MT/QA/Dialog  
  - (deep) learning algorithms  

- Materials with broad interests are welcome (e.g., tutorials form top conferences, high quality surveys).  

## For Presenters
- Please fill your slots in the [Agenda](#agenda) **at least one week** before your presentation.  
  - Use the format *[venue+year]title" in the Paper column (e.g. [ACL17]A Good Paper).   
  - Please upload your slides, and also add the links to them in the Slides column.  
- Besides technical novelties, please give enough background knowledge in case people are unfamiliar with the topic.    
- It would be great to keep your presentation within 60 min.   

## For Audiences   
- Please read abstract/introduction sections before the seminar  

## Agenda 

Week   | Speaker   | Paper   | Slides
:---:  | :---: | --- | :---:   
1    |李晨瑞 | 1. [ACL17] An End‐to‐End Model for Question Answering over  KnowledgeBase with Cross‐Attention Combining Global Knowledge </br> 2. [EMNLP17] Globally Normalized Reader | [slides1](https://github.com/AntNLP/seminar/blob/master/2017Fall/week1/An%20End-to-End%20Model%20for%20Question%20Answering%20over%20Knowledge%20Base%20with%20Cross-Attention%20Combining%20Global%20Knowledge-slide.pdf)</br> [slides2](https://github.com/AntNLP/seminar/blob/master/2017Fall/week1/Globally%20Normalized%20Reader-slide.pdf)
1    |周杰   | 1. [AAAI17] Interactive Neural Networks for Answer Selection in Community Question Answering  <br/> 2. [AAAI17] Improving Word Embeddings with Convolutional Feature Learning and Subword Information <br/>  3. [SIGIR17] Neural Ranking Models with Weak Supervision |  [slides](./week1/slides-ZHOUJie-0920.pdf)
2    |田俊峰 | [Cross-lingual] [Word Embedding] <br/> 1. [ArXiv13] Exploiting Similarities among Languages for Machine Translation <br/> 2. [ICLR17] OFFLINE BILINGUAL WORD VECTORS <br/> 3. [ACL17] Unsupervised Bilingual Lexicon Induction  | [slides](./week2/cross-lingual_embeddings/slides-cross-lingual-word-embeddings.pdf)
2    |陈嘉仪 | 1. [ACL16]Query Expansion with Locally-Trained Word Embeddings  <br/> 2. [SIGIR17]Relevance-Based Word Embedding | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week2/Word%20Embedding%20%26%20Query/Word%20Embedding%20%26%20Query.pdf)
3    |孙长志 | 1. [ACL17] Bandit Structured Prediction for Neural Sequence-to-Sequence Learning | [slides](https://github.com/AntNLP/seminar/blob/master/2017Fall/week3/slide-bandit-struct-pred-for-neural-seq2seq-learning.pdf)
3    |白庆春 | [Reading Comprehension] <br/> 1. [ACL2017 ] Attention-over-Attention Neural Networks for Reading Comprehension <br/> 2. [ACL2016] Text Understanding with the Attention Sum Reader Network <br/> 3. [ACL 2017] Gated-Attention Readers for Text Comprehension Codes: https://github.com/bdhingra/ga-reader | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week3/Cloze-style%20Reading%20Comprehension.pdf)
4    |周志恒 |  1. [EMNLP17] Towards Implicit Content-Introducing for Generative Short-Text Conversation Systems | [slides](https://github.com/AntNLP/seminar/blob/master/2017Fall/week4/slides-Conversation%20Systems.ppt)
4    |杨瑞达 | [knowledge base question answering] <br/> 1. [EMNLP2017] Recovering Question Answering Errors via Query Revision <br/> 2. [ACL 2016] Question answering on freebase via relation extraction and textual evidence <br/> 3. [ACL 2017] An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge  | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week4/2017.10.17%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AF%BE.pdf)
5    |纪焘   | [seq2seq parsing model][Multi-layer Attention] <br/> 1. [EMNLP17] Stack-based Multi-layer Attention for Transition-based Dependency Parsing <br/> [Self-play reinforcement learning]<br/> 1. [Nature17] Mastering the game of Go without human knowledge| [slides1](https://github.com/AntNLP/seminar/blob/master/2017Fall/week5/slides-Multi-layer-Attention.pdf) <br/> [slides2](https://github.com/AntNLP/seminar/blob/master/2017Fall/week5/slides-go.pdf)
5    |陈璐   | [Hierarchical Attention][Dual Attention] <br/> 1. [KDD17]A Context-aware Attention Network for Interactive Question Answering <br/> 2.  [SIGIR17]Leveraging Contextual Sentence Relations for Extractive Summarization Using a Neural Attention Model <br/> 3. [RecSys17]Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week5/b9432e50f882f834070492bffeef4064.pdf)
6    |周云晓 | [KR16] Commonsense Causal Reasoning between Short Texts  | [slides](./week6/slides-ZHOUYunXiao-commonsense_causal_reasoning.pdf)
6    |陈素   | [SIGIR17]Word-Entity Duet Representation for Document Ranking | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week6/Word-Entity%20Duet%20Representation%20for%20Document%20Ranking.pptx)
7    |杜雨沛 | [ACL16] Investigating Language Universal and Specific Properties in Word Embeddings | [slides](./week7/Pre_Nov.8th.pdf)
7    |盛艺暄 | [ACL17] Gated Self-Matching Networks for Reading Comprehension and Question Answering | [slides](./week7/R-NET.pptx)
8    |韦阳   | 1. [ACL17] Semi-supervised sequence tagging with bidirectional language models  <br/> 2. [ACL17]  Implicitly-Defined Neural Networks for Sequence Labeling | [slides1](./week8/slides-weiyang-TagLM.pdf)<br/>[slides2](./week8/slides-weiyang-INN.pdf)
8    |修玉环 | 1. [ICCV17] An Empirical Study of Language CNN for Image Captioning | [slides](./week8/Gu_An_Empirical_Study_ICCV_2017_slides.pdf)
9    |李晨瑞 | 1. [arxiv] DCN+: Mixed Objective and Deep Residual Coattention for Question Answering |[slides](https://github.com/AntNLP/seminar/blob/master/2017Fall/week9/DCN%2B%20MIXED%20OBJECTIVE%20AND%20DEEP%20RESIDUAL%20COATTENTION%20FOR%20QUESTION%20ANSWERING-slides.pdf)
9    |周杰   |  [GAN][Cross-domain] <br/> 1. [ICLR15] Unsupervised Domain Adaptation by Backpropagation <br/> 2.  [IJCAI17] End-to-End Adversarial Memory Network for Cross-domain Sentiment Classification | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week9/paper-sharing-zhoujie.pdf)
10    |田俊峰 | 1. [Overview of Multitask (from ruder)](http://ruder.io/multi-task/index.html) 2. [Multitask NLP](http://ruder.io/multi-task-learning-nlp/index.html) | [slides](./week10/A%20Survey%20of%20Multi-task%20Learning.pdf)
10    |陈嘉仪 | 1.[AAAI-16]Representation Learning of Knowledge Graphs with Entity Descriptions | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week10/Representation%20Learning%20With%20Entity%20Descriptions.pdf)
11    |孙长志 | [NIPS-17]Dynamic Routing Between Capsules | [slides](./week11/slide-dynamic-routing-between-capsules.pdf)
11    |杜雨沛 | [[EMNLP16] Inducing Domain-Speciﬁc Sentiment Lexicons from Unlabeled Corpora](http://www.anthology.aclweb.org/D/D16/D16-1057.pdf) | [slides](./Week11/Dec.6th_Seminar.pdf)
12    |盛艺暄 | [[arXiv]Fusionnet：Fusing via Fully-aware Attention with Application to Machine Comprehension](https://arxiv.org/pdf/1711.07341.pdf) | [slides](./week12/fusinnet.pptx)
12    |陈素   | [SIGIR17] Sentence-level Sentiment Classification with Weak Supervision  | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week12/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E8%AF%BE.ppt)
13    |纪焘   | [DP in TBDPs] <br/> 1. [EMNLP17] Fast(er) Exact Decoding and Global Training for Transition-Based Dependency Parsing via a Minimal Feature Set <br/> 2. [ACL11] Dynamic Programming Algorithms for Transition-Based Dependency Parsers | [slides](https://github.com/AntNLP/seminar/blob/master/2017Fall/week13/DP_in_TBDPs.pdf)
13    |陈璐   | [arXiv]DiSAN: Directional Self-Attention Network for RNN/CNN-free Language Understanding  | [slides](https://github.com/LucilleChen/seminar/blob/master/2017Fall/week13/Directional%20Self-Attention%20Network%20for%20RNN%EF%80%A2CNN-Free%20Language%20Understanding.pdf)
14    |陆兴武 | [AAAI17] A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues | [slides](./week14/A%20Hierarchical%20Latent%20Variable%20Encoder-Decoder%20Model%20for%20Generating%20Dialogues.pptx)
14    |许慧敏 | [AAAI17] Coupled Multi-Layer Attentions for Co-Extraction of Aspect and Opinion Terms.pdf | [slides](./week14/AAAI2017-Coupled%20Multi-Layer%20Attentions%20for%20Co-Extraction%20of%20Aspect%20and%20Opinion%20Terms.pptx)
15    |周志恒 | [AAAI18] Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory | [slides](https://github.com/zhou-zh/seminar/blob/master/2017Fall/week15/AAAI2018-ECM.ppt)
15    |杨瑞达 | 1.[EMNLP 2017] Question Generation for Question Answering <br/> 2.[ACL 2017] Improved Neural Relation Detection for Knowledge Base Question Answering |  [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week15/2018.1.3%20%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AF%BE.pdf)
16    |白庆春 | [ICLR18] Unsupervised Machine Translation Using Monolingual Corpora Only | [slides](https://github.com/12190143/seminar/blob/master/2017Fall/week16/Unsupervised%20Machine%20Translation%20Using%20Monolingual%20Corpora%20Only.pdf)
16    |周云晓 |  |
17    |韦阳   | 1. [EMNLP17] Cross-Lingual Transfer Learning for POS Tagging without Cross-Lingual Resources |
17    |修玉环 |  |
18    |孙问樵 |  |
18    |陈诗韵 |  |


---
Update 2017.10.24
### How to fill the slots and upload your slides?
- [creating-a-pull-request-from-a-fork/](https://help.github.com/articles/creating-a-pull-request-from-a-fork/)
- or you can contact:
  - SUN  Changzhi,
  - ZHOU Jie, 
  - TIAN Junfeng, rgtjf1 [AT] 163 [DOT] com
- any quesitons, please feel free to contact us.







