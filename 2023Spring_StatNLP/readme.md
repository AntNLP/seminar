# Statistical Natural Language Processing Seminar -- 2023 Spring

Time: **9:50, Thursday**

Venue: Tin Ka Ping Building 234 (田家炳楼234)

Welcome to StatNLP Seminar 2023 Spring. : )

## On Papers

- Please choose recent papers (2023, 2022, 2021) from top NLP/AI venues. A (incomplete) list is
  - NLP: ACL, TACL, EMNLP, NAACL, EACL
  - ML: ICML, NeurIPS, AISTATS, JMLR, ICLR
  - AI: AAAI, IJCAI
  - IR/DM: SIGIR, CIKM, WSDM, KDD, WWW
- While we are interested in a broad range of NLP/AI topics, this year we will pay special attentions on two themes
  - foundation models (pre-training models)
  - explaining methods
- We hope that, with high probability, you choose papers from [here](https://github.com/AntNLP/seminar/blob/master/2023Spring_StatNLP/2023-paper-list.md)
- other materials with broad interests are welcome (e.g., tutorials form top conferences, high-quality surveys).

## For Presenters

- Please fill your slots in the Agenda at least one week before your presentation.

  - Please format Paper fields with *[venue+year]title* (e.g. [ACL21]A Good Paper).
- Please upload your slides, and add links to them in Slides fields.
  
- Besides technical novelties, please give enough background knowledge in case people are unfamiliar with your topic.

- It would be great to keep your presentation within 60 min.

## For Audiences

- Please read abstract/introduction sections before the seminar.

## Agenda



| Week | Date | Speaker | Paper | Materials |
| ---- | ---- | ------- | ----- | --------- |
| 1    | 3.2  |    停电     |       |           |
| 2    | 3.9  |    李雨倩<br>汪杰     |   [\[EMNLP22\]Autoregressive Structured Prediction with Language Models](https://aclanthology.org/2022.findings-emnlp.70/) <br> [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)  |    [Slide](https://github.com/AntNLP/seminar/edit/master/2023Spring_StatNLP/week2/)       |
| 3    | 3.16  |    刘燕婷<br>兰孟烨   |   [\[ACL22\]Prompt for Extraction? PAIE: Prompting Argument Interaction for Event Argument Extraction](https://aclanthology.org/2022.acl-long.466/)<br>[\[EMNLP22\]Continual Training of Language Models for Few-Shot Learning](https://aclanthology.org/2022.emnlp-main.695/)    |    [Slide](https://github.com/AntNLP/seminar/edit/master/2023Spring_StatNLP/week3/)       |
| 4    | 3.23  |    顾轶洋<br>李雍   |   [\[ACL22\]There Are a Thousand Hamlets in a Thousand People’s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory](https://aclanthology.org/2022.acl-long.270/)<br>[\[EMNLP22\]InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning](https://aclanthology.org/2022.emnlp-main.33/)    |    [Slide](https://github.com/AntNLP/seminar/edit/master/2023Spring_StatNLP/week4/)       |
| 5    | 3.30  |    殷炜<br>魏旨航   |   [\[ACL22\]Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation](https://aclanthology.org/2022.acl-long.143/)<br>[\[ACL22\]FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning](https://aclanthology.org/2022.acl-long.592/)    |    [Slide](https://github.com/AntNLP/seminar/edit/master/2023Spring_StatNLP/week5/)       |
| 6    | 4.6  |    陈可迪<br>张燮弛   |   [GPTEVAL: NLG Evaluation using GPT-4 with Better Human Alignment](https://arxiv.org/abs/2303.16634)<br>[\[ACL22\]SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models](https://arxiv.org/abs/2303.08896)    |    [Slide](https://github.com/AntNLP/seminar/edit/master/2023Spring_StatNLP/week6/)       |
