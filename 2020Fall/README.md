# AntNLP Seminar -- 2020 Fall

Time: **1:00 pm - 3：30 pm, Friday**

Venue: B714, Science Building.

Welcome to AntNLP Seminar 2020 Fall : )

## On Papers

- Please choose recent papers (2020, 2019) from top NLP/AI venues. A (incomplete) list is
  - NLP: ACL, TACL, EMNLP, NAACL, EACL
  - ML:  ICML, NeurIPS, AISTATS, JMLR, ICLR
  - AI:  AAAI, IJCAI
  - IR/DM: SIGIR, CIKM, WSDM, KDD, WWW

- While we are interested in a broad range of NLP/AI topics, the followings (and a list [here](https://slack-files.com/T22T1UP8Q-FLT6K0WDV-c037db5283)) are of great importance

  - syntactic/semantic parsing
  - entity/relation/event extraction
  - distributed/distributional/compositional semantics
  - MT/QA/Dialog
  - graph neural networks
  - (deep) learning algorithms

- Materials with broad interests are welcome (e.g., tutorials form top conferences, high-quality surveys).

## For Presenters

- Please fill your slots in the [Agenda](#agenda) **at least one week** before your presentation.
  - Please format Paper fields with *[venue+year]title* (e.g. [ACL20]A Good Paper).
  - Please upload your slides, and add links to them in Slides fields.
- Besides technical novelties, please give enough background knowledge in case people are unfamiliar with your topic.
- It would be great to keep your presentation within 60 min.

## For Audiences

- Please read abstract/introduction sections before the seminar.

## Agenda

| Week   | Date | Speaker   | Paper   | Materials |
| :---:  | :---: | :---: | --- | :---: |
| 2      |  9.24 |  李鹏  | [CIKM19] Discerning Edge Influence for Network Embedding  | [link](https://dl.acm.org/doi/pdf/10.1145/3357384.3358044)|
| 3      |  10.01 |  Cancelled for National Day      |  | |
| 4       |  10.08 | Cancelled for National Day      |  ||
| 5      |  10.16 |    李鹏    |  [CIKM19] Discerning Edge Influence for Network Embedding   |[link](https://dl.acm.org/doi/pdf/10.1145/3357384.3358044)|
| 6      |  10.23 |    纪焘    |  Confidential : )   ||
| 7      |  10.30  |   韦阳   | [Survey] Compression Methods for Transformer-based Models   |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week7)|
| 8      | 11.06   |   周杰   | [Survey] Cross-modality semantic learning and reasoning    |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week8)|
| 9      |  11.13    |     黄子寅  | [Survey] Multi-Modal Information Extraction from Text, Semi-Structured, and Tabular Data    |[slides](https://sites.google.com/view/acl-2020-multi-modal-ie)|
| 10      |  11.20    |  刘宇芳    | [Survey] Papers about Probe and Attention   | [slides](https://drive.google.com/file/d/1TXkLzNYi_pAMXcwC5fNqiWh1Kgg485L1/view?usp=sharing)|
| 11      |  11.27    |   雷钲仪    | [Survey] Cross-Lingual Summarization   |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week11)|
| 12     |  12.04  |   汪贻俊    | Confidential : )   ||
| 13     |  12.10  |   汪贻俊    | Confidential : )  ||
| 14     |  12.18  |   白庆春   |  [EMNLP20] The Amazing World of Neural Language Generation  |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week13)|
| 15     |  12.25  |  Cancelled  |    ||
| 16     |  12.30  |   高怡    |  [Survey] Neural Network Explanation  |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week16)|
| 17     |  1.08  |    杨晰<br>纪焘   | [ACL20] A Novel Cascade Binary Tagging Framework for Relational Triple Extraction <br> Confidential : )    |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week17)|
| 18     |  1.15  |    韦阳   | [KBS21] AutoML: A survey of the state-of-the-art    |[link](https://mp.weixin.qq.com/s/nG_Mzlevs9ougnyeJyT38A)|
| 19     |  1.22  |    毛鑫   | [Symmetry19] Deep Metric Learning: A Survey  |[slides](https://github.com/AntNLP/seminar/tree/master/2020Fall/week19)|


---
## F.A.Q.

1. How to fill the slots and upload your slides?
- [creating-a-pull-request-from-a-fork/](https://help.github.com/articles/creating-a-pull-request-from-a-fork/)
- or you can contact:
  - Peng Li, <ruhao9805@gmail.com>
  - Tao Ji, <taoji.cs@gmail.com>
  - Yang Wei, <i@godweiyang.com>
- any quesitons, please feel free to contact us.
