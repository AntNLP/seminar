 # AntNLP Seminar -- 2018 Spring

Time: 6:00 pm, Thursday

Venue: 教书院106

Welcome to AntNLP Seminar 2018 Spring. :)

## On Papers

- Please choose recent papers (2018, 2017) from top NLP/AI venues. A (incomplete) list is
  - NLP: ACL, TACL, EMNLP, NAACL, EACL
  - ML:  ICML, NIPS, AISTATS, JMLR, ICLR
  - AI:  AAAI, IJCAI
  - IR/DM: SIGIR, CIKM, WSDM, KDD, WWW

- While we are interested in a broad range of NLP/AI topics, the followings (and a list [here](https://slack-files.com/T22T1UP8Q-F726RJERH-9a39cc3d9a)) are of great importance

  - syntactic/semantic parsing
  - entity/relation/event extraction
  - distributed/distributional/compositional semantics
  - MT/QA/Dialog
  - (deep) learning algorithms

- Materials with broad interests are welcome (e.g., tutorials form top conferences, high quality surveys).

## For Presenters

- Please fill your slots in the [Agenda](#agenda) **at least one week** before your presentation.
  - Please format Paper fields with *[venue+year]title* (e.g. [ACL17]A Good Paper).
  - Please upload your slides, and add links to them in Slides fields.
- Besides technical novelties, please give enough background knowledge in case people are unfamiliar with your topic.
- It would be great to keep your presentation within 60 min.

## For Audiences

- Please read abstract/introduction sections before the seminar.

## Agenda

Week   | Speaker   | Paper   | Slides
:---:  | :---: | --- | :---:
1      | 杜雨沛 | [[EMNLP17]Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints](Week1/Men-also-shopping.pdf)    |[slides](Week1/Pre_March1st.pdf)
2 | 韦阳 | [[NAACL16]Top-down Tree Long Short-Term Memory Networks](Week2/Top-down%20Tree%20Long%20Short-Term%20Memory%20Networks.pdf)<br/>[[TACL17]Head-Lexicalized Bidirectional Tree LSTMs](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week2/Head-Lexicalized%20Bidirectional%20Tree%20LSTMs.pdf) |[slides1](Week2/weiyang-slides-week2.pdf)<br/>[slides2](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week2/weiyang-slides-week2-2.pdf)
2 | 纪焘 | [[AAAI18]A Continuous Relaxation of Beam Search for End-to-end Training of Neural Sequence Models](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week2/A-Continuous-Relaxation-of-Beam-Search-for-E2E-Training-of-Neural-Sequence-Models.pdf) | [slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week2/Slides-A-Continuous-Relaxation-of-Beam-Search-for-E2E-Training-of-Neural-Sequence-Models.pdf)|
3 | 郑淇 | [[AAAI18]Variational Reasoning for Question Answering with Knowledge Graph](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week3/Variational-Reasoning-for-Question-Answering-with-Knowledge-Graph.pdf) | [slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week3/Slides-Variational-Reasoning-for-Question-Answering-with-Knowledge-Graph.pptx) |
3 | 陆兴武 | [[ACL17]Get To The Point: Summarization with Pointer-Generator Networks](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week3/Get%20To%20The%20Point%20Summarization%20with%20Pointer-Ge.pdf) | [slides](Week3/luxingwu-slides-week3.pdf.pdf) |
4 | 陈诗韵 | [Beyond Sparsity: Tree Regularization of Deep Models for Interpretability](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week4/Beyond%20Sparsity%20Tree%20Regularization%20of%20Deep%20Models%20for%20Interpretability%20.pdf) | [slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week4/Decision%20Tree.pdf) |
4 | 许慧敏 | [[ICLR18]Ask the Right Questions: Active Question Reformulation with Reinforcement Learning ](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week4/Ask%20the%20Right%20Questions_Active%20Question%20Reformulation%20with%20Reinforcement%20Learning.pdf) | |
5 | 张琪 | [[ACL17]Leveraging Knowledge Bases in LSTMs for Improving Machine Reading](https://github.com/12190143/seminar/blob/master/2018Spring/Week5/%5BACL2017%5DLeveraging%20Knowledge%20Bases%20in%20LSTMs%20for%20Improving%20Machine%20Reading.pdf);[[EMNLP17]World Knowledge for Reading Comprehension Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions](https://github.com/12190143/seminar/blob/master/2018Spring/Week5/%5BEMNLP2017%5DWorld%20Knowledge%20for%20Reading%20Comprehension%20Rare%20Entity%20Prediction%20with%20Hierarchical%20LSTMs%20Using%20External%20Descriptions.pdf) | [slides](https://github.com/12190143/seminar/blob/master/2018Spring/Week5/acl17%2Bemnlp17.pptx) |
5 | 周杰 | [[AAAI18]Learning Structured Representation for Text Classification via Reinforcement Learning](https://github.com/12190143/seminar/blob/master/2018Spring/Week5/AAAI2018-Learning%20Structured%20Representation%20for%20Text%20Classification%20via%20Reinforcement%20Learning%20.pdf); [[AAAI18]Reinforcement Learning for Relation Classification from Noisy Data](https://github.com/12190143/seminar/blob/master/2018Spring/Week5/AAAI2018-Reinforcement%20Learning%20for%20Relation%20Classification%20from%20Noisy%20Data.pdf)  | [slides](https://github.com/12190143/seminar/blob/master/2018Spring/Week5/AAAI18ReinforcementLearning.pdf) |
6 | 韦婷玉 | [[AAAI18]Convolutional 2D Knowledge Graph Embeddings](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week6/Convolutional%202D%20Knowledge%20Graph%20Embeddings.pdf) |[slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week6/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB-wty.pdf) |
6 | 孙长志 | [[EMNLP17]A Structured Learning Approach to Temporal Relation Extraction](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week6/a-structured-learning-approach-to-temporal-relation-extraction.pdf) | [slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week6/slide-tmp-rel-extraction.pdf)|
7 | 李晨瑞 | [[NIPS17]Deliberation Networks Sequence GenerationBeyond One‐Pass Decoding](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week7/%5BNIPS17%5DDeliberation%20Networks%20Sequence%20GenerationBeyond%20One%E2%80%90Pass%20Decoding.pdf)  |[slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week7/Deliberation%20Networks%20Sequence%20Generation%20Beyond%20One-Pass%20Decoding.pdf) |
7 | 纪雨 | [[ACL17]Linguistically Regularized LSTM for Sentiment Classification](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week7/Linguistically%20Regularized%20LSTM%20for%20Sentiment%20Classification.pdf) | [slides](https://github.com/AntNLP/seminar/blob/master/2018Spring/Week7/slides.pdf) |
8 | 田俊峰 | [[NIPS17]Attention Is All You Need](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) | [slides](Week8/Attention%20Is%20All%20You%20Need.pdf) |
8 | 张凉 | [[AAAI18]Neural Response Generation with Dynamic Vocabularies](Week8/neural%20response%20generation%20with%20dynamic%20vocabularies.pdf) | [slides](Week8/DVS2S.pdf) |
9 | 郁建峰 | [[SIGIR16]Learning to Respond with Deep Neural Networks for Retrieval-Based Human-Computer Conversation System](http://www.ruiyan.me/pubs/SIGIR2016.pdf)  | | [slides](Week10/郁建峰slides.pdf)
9 | 战蕾 | [[SIGIR17]Learning to Rank Question Answer Pairs with Holographic Dual LSTM](https://arxiv.org/pdf/1707.06372.pdf) | [slides](Week10/战蕾slides.pdf) |
10 | 李芸 |  | |
10 | 姚振旭 | [[RecSys17]A Multi-criteria Recommender System Exploiting Aspect-based Sentiment Analysis of Users’ Reviews](http://delivery.acm.org/10.1145/3110000/3109905/p321-musto.pdf?ip=219.228.146.121&id=3109905&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E035EACC12F524219%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1526006819_822eb0ff43f60c32a32c1faee37d33a5) | [slides](Week11/51174506037姚振旭.pdf) |
11 | 杜雨沛 |[[NIPS16]Equality of opportunity in supervised learning](https://arxiv.org/pdf/1610.02413.pdf) | |
11 | 韦阳 | [EACL17]K-best Iterative Viterbi Parsing | |
12 | 陆兴武 |  | |
12 | 郑淇 |  | |
13 | 纪焘 |  | |
13 | 周杰 |  | |
14 | 许慧敏 |  | |
14 | 田俊峰 |  | |
15 | 李晨瑞 |  | |
15 | 孙长志 |  | |
16 | 陈诗韵 |  | |
16 | 张琪 |  | |
17 | 韦婷玉 |  | |
17 | 纪雨 |  | |
18 | 战蕾 |  | |
18 | 郁建峰 |  | |

---
## F.A.Q.

1. How to fill the slots and upload your slides?
- [creating-a-pull-request-from-a-fork/](https://help.github.com/articles/creating-a-pull-request-from-a-fork/)
- or you can contact:
  - SUN  Changzhi,
  - ZHOU Jie, 
  - TIAN Junfeng, rgtjf1 [AT] 163 [DOT] com
- any quesitons, please feel free to contact us.
